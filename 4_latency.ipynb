{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "source": [
    "## ランダムアクセス用の配列生成"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_shuffle(max_size, shuffle=False):\n",
    "\twords = list(range(max_size))\n",
    "\n",
    "\tif(shuffle):\n",
    "\t\trandom.shuffle(words)\n",
    "\treturn words\n",
    "\n",
    "def shuffle_warp_align(buffer_size, warp_size=32, shuffle=False):\n",
    "\tassert buffer_size % warpsize == 0\n",
    "\n",
    "\tpage_size = buffer_size // warpsize\n",
    "\tbuffer = np.zeros(buffer_size)\n",
    "\n",
    "\tfor j in range(warp_size):\n",
    "\t\twords = words_shuffle(page_size, shuffle)\n",
    "\n",
    "\t\tfor i in range(page_size):\n",
    "\t\t\tbuffer[words[i % page_size] * warp_size + j] = words[(i+1) % page_size] * warpsize + j\n",
    "\treturn buffer\n",
    "\t\n",
    "def shuffle_array_align(buffer_size, shuffle=False):\n",
    "\tbuffer = np.zeros(buffer_size)\n",
    "\twords = words_shuffle(buffer_size, shuffle)\n",
    "\n",
    "\tfor i in range(buffer_size):\n",
    "\t\tbuffer[words[i % size]]=words[(i + 1) % buffer_size]\n",
    "\n",
    "\t"
   ]
  },
  {
   "source": [
    "## メモリレイテンシ計測用カーネルの実行"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gpu_memcpy_time(\n",
    "        buffer_gpu, gputime_gpu, dummy_gpu, buffer_size, \n",
    "        grid_size=128, block_size=256, \n",
    "        partition_num=16, copy_iter=16,\n",
    "        is_random=False):\n",
    "    latency_mod = SourceModule(\"\"\"\n",
    "    __global__ void latency_calc(\n",
    "            int *buffer, int* gputime, int* dummy, int repeat_num)\n",
    "    {\n",
    "    \tunsigned int t1, t2;\n",
    "        int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "        t1 = clock();\n",
    "        for( int rep=0; rep<repeat_num; rep++ )\n",
    "        {\n",
    "            index = buffer[index];\n",
    "        }\n",
    "        t2 = clock();\n",
    "\n",
    "        gputime[0] = t2-t1;\n",
    "        dummy[0] = index;\n",
    "    }\n",
    "    \"\"\")\n",
    "\n",
    "    latency_kernel = latency_mod.get_function(\"latency_calc\")\n",
    "    latency_kernel.prepare(\"PPPi\")\n",
    "    latency_kernel.set_cache_config(pycuda.driver.func_cache.PREFER_L1)\n",
    "\n",
    "    buf_num = buffer_size // 4\n",
    "    kernel_times = list()\n",
    "    clock_times = list()\n",
    "    for iter in range(copy_iter+1):\n",
    "        if is_random:\n",
    "            loop_num = buffer_size * partition_num // 32\n",
    "            buffer_cpu = shuffle_warp_align(buffer_size, False)\n",
    "        else:\n",
    "            loop_num = buffer_size * partition_num // 32 // 32\n",
    "            buffer_cpu = shuffle_array_align(buffer_size, True)\n",
    "\n",
    "        cuda.memcpy_htod(buffer_gpu, buffer_cpu)\n",
    "\n",
    "        ev_start  = drv.Event()\n",
    "        ev_finish = drv.Event()\n",
    "\n",
    "        ev_start.record()\n",
    "        latency_kernel.prepared_call(\n",
    "            (grid_size,1), (block_size,1,1),\n",
    "            buffer_gpu, gputime_gpu, dummy_gpu, np.int32(loop_num)\n",
    "        )\n",
    "        ev_finish.record()\n",
    "        ev_finish.synchronize()\n",
    "\n",
    "        gputime_cpu = np.zeros(1).astype(np.int32)\n",
    "        dummpy_cpu = np.zeros(1).astype(np.int32)\n",
    "        cuda.memcpy_dtoh(gputime_cpu, gputime_gpu)\n",
    "        cuda.memcpy_dtoh(dummpy_cpu, dummpy_gpu)\n",
    "      \n",
    "        if iter != 0:\n",
    "            kernel_times.append(ev_start.time_till(ev_finish) * 0.001)\n",
    "            clock_times.append(gputime_cpu)\n",
    "    return times, clocks"
   ]
  },
  {
   "source": [
    "## 計測するバッファサイズ"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10.0 - 30.0: 10 step\n"
     ]
    }
   ],
   "source": [
    "mem_step = 10\n",
    "min_mem_size = 1024\n",
    "max_mem_size = 1 * 1024 * 1024 * 1024\n",
    "\n",
    "min_mem_log2 = np.log2(min_mem_size)\n",
    "max_mem_log2 = np.log2(max_mem_size)\n",
    "\n",
    "# step size: 10\n",
    "print(f\"{min_mem_log2} - {max_mem_log2}: {mem_step} step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "devdat = pycuda.tools.DeviceData()\n",
    "copy_buffers = np.logspace(min_mem_log2, max_mem_log2, mem_step, base=2)\n",
    "copy_buffers_align = [devdat.align(buf, word_size = 4) for buf in copy_buffers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_buffer_size = max(copy_buffers_align)\n",
    "buffer_gpu = drv.mem_alloc(max_buffer_size)\n",
    "gputime_gpu = drv.mem_alloc(np.dtype(np.int32).itemsize)\n",
    "dummy_gpu = drv.mem_alloc(np.dtype(np.int32).itemsize)"
   ]
  },
  {
   "source": [
    "## コアレスアクセス"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_latency(time_df, target=\"buffer_size\"):\n",
    "    mean_df = time_df.groupby([target], as_index=False).mean()\n",
    "\n",
    "    band_dict = defaultdict(list)\n",
    "    for row in mean_df.itertuples():\n",
    "        band_dict[target].append(getattr(row, target))\n",
    "        band_dict[\"latency\"].append(row.clock_time)\n",
    "    band_df = pd.DataFrame(band_dict)\n",
    "\n",
    "    ax = sns.catplot(x=target, y=\"latency\", data=band_df, kind=\"bar\")\n",
    "    ax = ax.set_xticklabels(rotation=90)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pycuda.driver.Context.get_device()\n",
    "memory_clock_rate = dev.get_attribute(pycuda._driver.device_attribute.MEMORY_CLOCK_RATE)\n",
    "\n",
    "clock_dict = defaultdict(list)\n",
    "for buffer_size in copy_buffers_align:\n",
    "    _, clocks = calc_gpu_memcpy_time(buffer_gpu, gputime_gpu, dummy_gpu, max_buffer_size)\n",
    "    for iter, clock in enumerate(clocks):\n",
    "        clock_df[\"buffer_size\"].append(buffer_size)\n",
    "        clock_df[\"iteration\"].append(iter)\n",
    "        clock_df[\"clock_time\"].append(clock/memory_clock_rate)\n",
    "clock_df = pd.DataFrame(time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'time_df' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e059536b7f71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_bandwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"buffer_size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'time_df' is not defined"
     ]
    }
   ],
   "source": [
    "show_latency(clock_df, target=\"buffer_size\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## ランダムアクセス"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pycuda.driver.Context.get_device()\n",
    "memory_clock_rate = dev.get_attribute(pycuda._driver.device_attribute.MEMORY_CLOCK_RATE)\n",
    "\n",
    "clock_dict = defaultdict(list)\n",
    "for buffer_size in copy_buffers_align:\n",
    "    _, clocks = calc_gpu_memcpy_time(buffer_gpu, gputime_gpu, dummy_gpu, max_buffer_size, is_random=True)\n",
    "    for iter, clock in enumerate(clocks):\n",
    "        clock_df[\"buffer_size\"].append(buffer_size)\n",
    "        clock_df[\"iteration\"].append(iter)\n",
    "        clock_df[\"clock_time\"].append(clock/memory_clock_rate)\n",
    "clock_df = pd.DataFrame(time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_latency(clock_df, target=\"buffer_size\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}